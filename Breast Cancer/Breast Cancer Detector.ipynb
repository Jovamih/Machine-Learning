{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deteccion del Cancer de Mama en la ciudad de Winsconsin\n",
    "* El siguiente analisis predictivo usaremos heramientas de Machine learning para lograr detectar el Cancer\n",
    "  de mama en funcion de sus carateristicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Planteamiento del problema\n",
    "* Obteneer un modelo de machine learning para hallar el cancer de mama a temprana edad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metricas de evaluacion\n",
    "* Al tratarse de un problema de clasificacion (Tal y como cataloga el repositorio UCI) usaremos metricas como **accuracy** ,**f1**,**recall**,**precision**. La mas importante es **f1** ya que tiene mejor desenvolvimiento con los datos desbalanceados, y orientacion en la metrica de falsos positivos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparacion de datos\n",
    "### 3.1 Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#cargamos los datos\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from pandas_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names=['Sample-code-number','Clump-Thickness','USize','UShape','Marginal-adhesion','SingleEpSize','BareNuclei','BlandCh','NormalNucleoi','Mitoses','Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\",names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample-code-number</th>\n",
       "      <th>Clump-Thickness</th>\n",
       "      <th>USize</th>\n",
       "      <th>UShape</th>\n",
       "      <th>Marginal-adhesion</th>\n",
       "      <th>SingleEpSize</th>\n",
       "      <th>BareNuclei</th>\n",
       "      <th>BlandCh</th>\n",
       "      <th>NormalNucleoi</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample-code-number  Clump-Thickness  USize  UShape  Marginal-adhesion  \\\n",
       "0             1000025                5      1       1                  1   \n",
       "1             1002945                5      4       4                  5   \n",
       "2             1015425                3      1       1                  1   \n",
       "3             1016277                6      8       8                  1   \n",
       "4             1017023                4      1       1                  3   \n",
       "\n",
       "   SingleEpSize BareNuclei  BlandCh  NormalNucleoi  Mitoses  Class  \n",
       "0             2          1        3              1        1      2  \n",
       "1             7         10        3              2        1      2  \n",
       "2             2          2        3              1        1      2  \n",
       "3             3          4        3              7        1      2  \n",
       "4             2          1        3              1        1      2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample-code-number</th>\n",
       "      <th>Clump-Thickness</th>\n",
       "      <th>USize</th>\n",
       "      <th>UShape</th>\n",
       "      <th>Marginal-adhesion</th>\n",
       "      <th>SingleEpSize</th>\n",
       "      <th>BlandCh</th>\n",
       "      <th>NormalNucleoi</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.990000e+02</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.071704e+06</td>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.170957e+05</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.163400e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.706885e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.171710e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.238298e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345435e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sample-code-number  Clump-Thickness       USize      UShape  \\\n",
       "count        6.990000e+02       699.000000  699.000000  699.000000   \n",
       "mean         1.071704e+06         4.417740    3.134478    3.207439   \n",
       "std          6.170957e+05         2.815741    3.051459    2.971913   \n",
       "min          6.163400e+04         1.000000    1.000000    1.000000   \n",
       "25%          8.706885e+05         2.000000    1.000000    1.000000   \n",
       "50%          1.171710e+06         4.000000    1.000000    1.000000   \n",
       "75%          1.238298e+06         6.000000    5.000000    5.000000   \n",
       "max          1.345435e+07        10.000000   10.000000   10.000000   \n",
       "\n",
       "       Marginal-adhesion  SingleEpSize     BlandCh  NormalNucleoi     Mitoses  \\\n",
       "count         699.000000    699.000000  699.000000     699.000000  699.000000   \n",
       "mean            2.806867      3.216023    3.437768       2.866953    1.589413   \n",
       "std             2.855379      2.214300    2.438364       3.053634    1.715078   \n",
       "min             1.000000      1.000000    1.000000       1.000000    1.000000   \n",
       "25%             1.000000      2.000000    2.000000       1.000000    1.000000   \n",
       "50%             1.000000      2.000000    3.000000       1.000000    1.000000   \n",
       "75%             4.000000      4.000000    5.000000       4.000000    1.000000   \n",
       "max            10.000000     10.000000   10.000000      10.000000   10.000000   \n",
       "\n",
       "            Class  \n",
       "count  699.000000  \n",
       "mean     2.689557  \n",
       "std      0.951273  \n",
       "min      2.000000  \n",
       "25%      2.000000  \n",
       "50%      2.000000  \n",
       "75%      4.000000  \n",
       "max      4.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Sample-code-number  699 non-null    int64 \n",
      " 1   Clump-Thickness     699 non-null    int64 \n",
      " 2   USize               699 non-null    int64 \n",
      " 3   UShape              699 non-null    int64 \n",
      " 4   Marginal-adhesion   699 non-null    int64 \n",
      " 5   SingleEpSize        699 non-null    int64 \n",
      " 6   BareNuclei          699 non-null    object\n",
      " 7   BlandCh             699 non-null    int64 \n",
      " 8   NormalNucleoi       699 non-null    int64 \n",
      " 9   Mitoses             699 non-null    int64 \n",
      " 10  Class               699 non-null    int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample-code-number    0\n",
       "Clump-Thickness       0\n",
       "USize                 0\n",
       "UShape                0\n",
       "Marginal-adhesion     0\n",
       "SingleEpSize          0\n",
       "BareNuclei            0\n",
       "BlandCh               0\n",
       "NormalNucleoi         0\n",
       "Mitoses               0\n",
       "Class                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veamos si hay nulos\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#por suerte no hay nulos.\n",
    "#pero detectaos que '?' es detectado como nulo\n",
    "data.replace('?',np.nan,inplace=True)\n",
    "#Entonces tenemosque ir a la exploracion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample-code-number     0\n",
       "Clump-Thickness        0\n",
       "USize                  0\n",
       "UShape                 0\n",
       "Marginal-adhesion      0\n",
       "SingleEpSize           0\n",
       "BareNuclei            16\n",
       "BlandCh                0\n",
       "NormalNucleoi          0\n",
       "Mitoses                0\n",
       "Class                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample-code-number    0\n",
       "Clump-Thickness       0\n",
       "USize                 0\n",
       "UShape                0\n",
       "Marginal-adhesion     0\n",
       "SingleEpSize          0\n",
       "BareNuclei            0\n",
       "BlandCh               0\n",
       "NormalNucleoi         0\n",
       "Mitoses               0\n",
       "Class                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#como son discretas lo remplazaremos por la moda, el valor mas frecuente\n",
    "moda=data['BareNuclei'].mode()[0]\n",
    "data['BareNuclei']=data['BareNuclei'].replace(np.nan,moda)\n",
    "\n",
    "#y verificamos su asignacion\n",
    "data.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['Sample-code-number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La prescencia de valores duplicados se realiza en la exploracion de datos como luego de la seleccion de caracteriticas : Ojo. Importante\n",
    "data.drop_duplicates(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#una vez borrado los elementos redundantes\n",
    "#debido a que nos nos muestra el codigo del numero de muestra 'Sample-code-number'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Exploracion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1re enfoque: Hacerlo todo manual y deectar valor atipicos\n",
    "#podemos apreciar el ID qu no guarda relacion con nada, pero lo dejaremos para la Feature_selection\n",
    "#como los valores hacen referencia a grados, \n",
    "\n",
    "fig,axes=plt.subplots(5,2,figsize=(10,20 ))\n",
    "for ax,column in zip(axes.flat,data.columns[1:]):\n",
    "    sns.countplot(data[column],ax=ax)\n",
    "\n",
    "\n",
    "#2doEnfoque: Usar pandas-profiling (Libreria que hace el analisis de forma automatica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ya habiendo analizado las clases, verificaremos las categorias de target\n",
    "data['Class'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    452\n",
       "4    238\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mediana</th>\n",
       "      <th>Moda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clump-Thickness</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USize</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UShape</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marginal-adhesion</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SingleEpSize</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BareNuclei</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlandCh</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalNucleoi</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitoses</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Mediana Moda\n",
       "Clump-Thickness        4.0    1\n",
       "USize                  1.0    1\n",
       "UShape                 1.0    1\n",
       "Marginal-adhesion      1.0    1\n",
       "SingleEpSize           2.0    2\n",
       "BareNuclei             1.0    1\n",
       "BlandCh                3.0    2\n",
       "NormalNucleoi          1.0    1\n",
       "Mitoses                1.0    1\n",
       "Class                  2.0    2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usariamos las metricas mas conocidas, como media, e incluso analisi de outliers. Pero observamos muchas variables discretas y no continuas\n",
    "result={'Mediana':list(),\n",
    "        'Moda':list()}\n",
    "for column in data.columns[1:]:\n",
    "    result['Mediana'].append(data[column].median())\n",
    "    result['Moda'].append(data[column].mode()[0])\n",
    "    \n",
    "pd.DataFrame(result,index=data.columns[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Seleccion de caracteristicas\n",
    "* Al tratarse de un problema de clasificacion con entradas numericas y salidas categoricas\n",
    "usaremos ANOVA reflejado en f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['BareNuclei']=data['BareNuclei'].astype('int64') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminaremos los registros duplicados. Ojo si en el problema se tratn Series temporales, no se debe elimnar registros identicos\n",
    "#porue afectaria al modelo, En este caso no hay relacion alguna con el tiempo\n",
    "data.duplicated().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop_duplicates(inplace=True)\n",
    "data=data.drop('Sample-code-number',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformamos las salidas categoricas 4 (maligno) a 0 y 2(Benigno) a 0) de esta manera preservamos la codificacion categorica\n",
    "data=data.replace({4:1,2:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 690 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype\n",
      "---  ------             --------------  -----\n",
      " 0   Clump-Thickness    690 non-null    int64\n",
      " 1   USize              690 non-null    int64\n",
      " 2   UShape             690 non-null    int64\n",
      " 3   Marginal-adhesion  690 non-null    int64\n",
      " 4   SingleEpSize       690 non-null    int64\n",
      " 5   BareNuclei         690 non-null    int64\n",
      " 6   BlandCh            690 non-null    int64\n",
      " 7   NormalNucleoi      690 non-null    int64\n",
      " 8   Mitoses            690 non-null    int64\n",
      " 9   Class              690 non-null    int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 79.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2217c109c48>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veamos la correlacion de variables que funciona con variables numericas y en el caso de la regression\n",
    "corr=data.corr(method='pearson')\n",
    "\n",
    "#os resultados seran erroneos debido que no se ha hecho la seleccion adeuada para el tipo de problema adecuada\n",
    "#Entradas numericas- salidas categoricas--> Problema de clasificacion: Se usara el coeficiente de correlacion de ANOVA **f_classif**\n",
    "sns.heatmap(corr,annot=True,fmt='0.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* podemos observar que los resultados seerian alentadores si en verdad se tratara de una regression. Por lo que las usaremos la seleccion de caracteristicas adecuadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select(X,y,func=None,n='all'):\n",
    "    fs=SelectKBest(score_func=func,k=n)\n",
    "    fs.fit(X,y)\n",
    "    columns=data.columns[:-1] \n",
    "    plt.bar(np.arange(len(columns)),fs.scores_)\n",
    "    plt.xticks(np.arange(len(columns)),columns)\n",
    "    plt.xlabel('Columnas')\n",
    "    plt.ylabel('Score')\n",
    "    return fs #retornamos el seleccionador de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicated(X,y):\n",
    "    #concatenamos los datos para poder identificar duplicados a nivel DataFrame\n",
    "    data=pd.concat([pd.DataFrame(X),pd.Series(y)],axis=1,join='inner')\n",
    "    print('Rows duplicated: {0}'.format(data.duplicated().sum()))\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    #retornamos los datos sin duplicados\n",
    "    return data.iloc[:,:-1].values,data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtenemos los datos\n",
    "X=data.drop('Class',axis=1).values\n",
    "y=data['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=feature_select(X,y,func=f_classif,n='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 692.03686626,  903.86091471,  931.69646715,  444.63808816,\n",
       "        567.66778993, 1110.55952446,  638.35457582,  594.56207142,\n",
       "         83.65208059])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.scores_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los resultados son muy alentadores, puesto que incluso el valor mas bajo (Puntaje para 'Mitoses') tiene una relacion significativa con la variable de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#veamos que pasa cuando separamos los datos antes\n",
    "from sklearn.model_selection  import train_test_split\n",
    "Xtrain,Xtest,Ytrain,Ytest= train_test_split(X,y,random_state=0,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=feature_select(Xtrain,Ytrain,func=f_classif,n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "fs_mutual= feature_select(Xtrain,Ytrain,func=mutual_info_classif,n='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([533.31599177, 761.30845246, 722.63425743, 322.87668131,\n",
       "       455.51000484, 834.82942892, 507.13106619, 441.77958374,\n",
       "        66.23576012])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29761687, 0.38005312, 0.33461326, 0.2120713 , 0.29985018,\n",
       "       0.34642189, 0.29744601, 0.26479189, 0.13630595])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#puntaj para ganancia mutua de informacion\n",
    "fs_mutual.scores_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podemos ver claramente que ahora 'mitoses' es menos relevante, la dejaremos asi, para luego evaluar el rendimiento del modelo\n",
    "# y si hay sobreajuste o subajuste ya tendremos a la caracteristica candidata para la eliminacion\n",
    "#unas horas despues....... Verificaremos los datos\n",
    "#eliminamos 'Mitoses' de los datos\n",
    "data=data.drop('Mitoses',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=fs.transform(X)\n",
    "Xtrain=fs.transform(Xtrain)\n",
    "Xtest=fs.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows duplicated: 258\n"
     ]
    }
   ],
   "source": [
    "X,y=drop_duplicated(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    237\n",
       "0    195\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora balancearemos los datos.Puesto que\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Ytrain=smote.fit_sample(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([189, 189], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Transformacion de datos\n",
    "\n",
    "Una vez elejido las mejoras carateristicas se procede a:\n",
    "* Codificar las Variables de entrada seleccionadas (Si existen dummies). Ojo: La variable de salida al ser categorica ya fue transformada en el proceso de seleccion de caracteristicas y en  mi opinion codificarla para hacer las prueebas correspondientes es una buena practica que suelo hacer a menudo.\n",
    "* Escalar variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Antes solia hacer el escalado, pero es mejor hacerlo con Pipelines, en el que los escalo antes de entrenarlos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccion del modelo\n",
    "\n",
    "* Haremos un Test con el mejor modelo sobre todos los datos, comparandolos de forma equitativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Elejir el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_model=['Logistic','DecisionTree','RandomForest','SupportVector','KNN']\n",
    "list_model=[LogisticRegression(solver='lbfgs',class_weight='balanced'),\n",
    "            DecisionTreeClassifier(class_weight='balanced'),\n",
    "            RandomForestClassifier(class_weight='balanced'),\n",
    "            SVC(class_weight='balanced'),\n",
    "            KNeighborsClassifier()\n",
    "            \n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#la seleccion del modelo se hace con todos los datos, tanto de entrenamiento como de Prueba\n",
    "kfold=StratifiedKFold(n_splits=10,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_model(names_model,list_model,scoring=('accuracy'),X=0,y=0,cv=0):\n",
    "    results={score:{'train':[],\n",
    "                    'test':[]\n",
    "                   } for score in scoring}\n",
    "    for name,model in zip(names_model,list_model):\n",
    "        pipe_model=make_pipeline(StandardScaler(),model)\n",
    "\n",
    "        scores=cross_validate(pipe_model,X ,y,\n",
    "                              cv=cv,\n",
    "                              scoring=scoring,\n",
    "                              n_jobs=-1,\n",
    "                              return_train_score=True,\n",
    "                             )\n",
    "        scores=pd.DataFrame(scores)\n",
    "        #print(scores.head())\n",
    "        for score in scoring:\n",
    "            for site,sc in zip(['train','test'],[score,score]):\n",
    "                results[score][site].append(scores[site+'_'+sc].mean())\n",
    "        print(\"{0} Analizado.. Ok\".format(name))\n",
    "    \n",
    "    rs={key: pd.DataFrame(v,index=names_model) for key,v in results.items()}\n",
    "    return pd.concat(rs,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Analizado.. Ok\n",
      "DecisionTree Analizado.. Ok\n",
      "RandomForest Analizado.. Ok\n",
      "SupportVector Analizado.. Ok\n",
      "KNN Analizado.. Ok\n"
     ]
    }
   ],
   "source": [
    "data_score=select_best_model(names_model,list_model,scoring=('accuracy','f1'),X=X,y=y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.948305</td>\n",
       "      <td>0.942230</td>\n",
       "      <td>0.952215</td>\n",
       "      <td>0.946731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SupportVector</th>\n",
       "      <td>0.960392</td>\n",
       "      <td>0.935254</td>\n",
       "      <td>0.963800</td>\n",
       "      <td>0.941163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.954828</td>\n",
       "      <td>0.939122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy                  f1          \n",
       "                  train      test     train      test\n",
       "Logistic       0.948305  0.942230  0.952215  0.946731\n",
       "DecisionTree   1.000000  0.907452  1.000000  0.915985\n",
       "RandomForest   1.000000  0.935307  1.000000  0.941290\n",
       "SupportVector  0.960392  0.935254  0.963800  0.941163\n",
       "KNN            0.950617  0.932981  0.954828  0.939122"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2217ed5bf48>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_score['accuracy'].plot(kind='bar',title='Accuracy scores')\n",
    "data_score['f1'].plot(kind='bar',title='F1 scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* De los graficos anteriores podemos deducir que por cada metrica y conjunto de datos independiente. Tenemos un margen de sobreajuste a los datos .\n",
    "\n",
    "* La razon por la que elejimos la metrica **'F1'** es porque es maz veraz en los resultados que **'accuracy'**, es porque nuestro conjunto de datos presenta datos desbalanceados.\n",
    "* Entonces tomando en cuenta el mejor puntaje en la **F1**,( sin dejar de lado el **accuracy**), la mejor puntuacion la posee **Logistic Regression**, seguido de **Support Vector Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ajustar el modelo\n",
    "* Esta parte consta de ajustar los hiperparametros del modelo\n",
    "* Validaciones cruzadas para el conjunto de Train y Validacion (Implicita)\n",
    "* El conjunto de Testeo debe estar excluido de los resltado de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "model=Pipeline(steps=[\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('KNeighbors',KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora veamos el comportamiento del modelo en el conjunto de entrenamiento que es el que se utilizara de apartir en adelante\n",
    "def cross_validation(model,X=None,y=None,scoring=tuple(),cv=None):\n",
    "\n",
    "    scores=cross_validate(model,X,y,\n",
    "                              cv=cv,\n",
    "                              scoring=scoring,\n",
    "                              n_jobs=-1,\n",
    "                              return_train_score=True,\n",
    "                             )\n",
    "    score_mean=pd.DataFrame(scores).mean(axis=0)\n",
    "    score_std=pd.DataFrame(scores).std(axis=0)\n",
    "    scores=pd.concat([score_mean,score_std],axis=1,keys=['Mean','Std'])\n",
    "    \n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Mean       Std\n",
      "fit_time        0.009377  0.008071\n",
      "score_time      0.013684  0.004188\n",
      "test_accuracy   0.941963  0.034625\n",
      "train_accuracy  0.953855  0.005841\n",
      "test_f1         0.940922  0.035730\n",
      "train_f1        0.953343  0.005930\n"
     ]
    }
   ],
   "source": [
    "cross_validation(model,Xtrain,Ytrain,scoring=('accuracy','f1'),cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos que esta sobreajustado un poco asi que lo solucionaremos\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_parameters(model,param_grid,scoring='accuracy',cv=7,X=None,y=None): \n",
    "    grid=GridSearchCV(estimator=model,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring=scoring,\n",
    "                      cv=kfold,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=2\n",
    "                     )\n",
    "    grid.fit(X,y);\n",
    "    print(\"Best Parameters: {0}\".format(grid.best_params_))\n",
    "    print(\"Best score:      {0}\".format(grid.best_score_))\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'KNeighbors__n_neighbors': 5}\n",
      "Best score:      0.9419630156472261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    4.8s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid=dict(KNeighbors__n_neighbors=np.arange(5,12),\n",
    "               )\n",
    "grid=tuning_parameters(model,param_grid,scoring='accuracy',cv=kfold,X=Xtrain,y=Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=grid.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Mean       Std\n",
      "fit_time        0.011149  0.011151\n",
      "score_time      0.028250  0.022078\n",
      "test_accuracy   0.941963  0.034625\n",
      "train_accuracy  0.953855  0.005841\n",
      "test_f1         0.940922  0.035730\n",
      "train_f1        0.953343  0.005930\n"
     ]
    }
   ],
   "source": [
    "cross_validation(model,Xtrain,Ytrain,scoring=('accuracy','f1'),cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_parameter(model,X,y,param_name,param_range,cv=7):\n",
    "    \n",
    "    train_score,test_score=validation_curve(model,Xtrain,Ytrain,\n",
    "                                       param_name='forest__min_samples_split',\n",
    "                                        param_range=np.arange(0.1,0.7,10),\n",
    "                                        cv=kfold,\n",
    "                                        n_jobs=-1\n",
    "                                       )\n",
    "    train_mean=train_score.mean(axis=1)\n",
    "    train_std=train_score.std(axis=1)\n",
    "\n",
    "    test_mean=test_score.mean(axis=1)\n",
    "    test_std=test_score.std(axis=1)\n",
    "\n",
    "    plt.plot(param_range,train_mean,'-b',label='Train')\n",
    "    plt.fill_between(param_range,train_mean+train_std,train_mean-train_std,alpha=0.3)\n",
    "\n",
    "    plt.plot(param_range,test_mean,'-r',label='Test')\n",
    "    plt.fill_between(param_range,test_mean+test_std,test_mean-test_std,alpha=0.3)\n",
    "    plt.legend(loc='best')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Validacion del modelo final\n",
    "* A esta fase se llega solo si se logra obtener un equilibrio entre el sobreajuste ysubajuste de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtrain,Ytrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred=model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        39\n",
      "           1       0.96      0.94      0.95        48\n",
      "\n",
      "    accuracy                           0.94        87\n",
      "   macro avg       0.94      0.94      0.94        87\n",
      "weighted avg       0.94      0.94      0.94        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Ytest,Ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  2]\n",
      " [ 3 45]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2217ed5bf48>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=['benign','malign']\n",
    "conf=confusion_matrix(Ytest,Ypred)\n",
    "print(conf)\n",
    "sns.heatmap(conf,annot=True,fmt='.2f',xticklabels=labels,yticklabels=labels,square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#est es increible podemos notar resultados muy prometedores para la solucion de nuestro problema. \n",
    "#Ya existe un equilibrio entre sesgo y varianza. ...Pero nos damos cuenta de algo. Los valores duplicados en el datset\n",
    "#por lo tanto procedemos a guardar el modelo\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breast_cancerKNeighborsV0.1.pkl']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model,'breast_cancerKNeighborsV0.1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maana continuamos con la implementacion del mejor modelo, puesto que echamos de menos los duplicacdos\n",
    "#con la elimnacion de los duplicados obtuvimos datos mas sinceros debidoa que a la precesnia de duplicados cierta proporcion se destinaba\n",
    "#al los datos de entreamiento y a otra a la de Test, lo que impedi un poco al enfrentarse a datos reales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking de modelos ML\n",
    "* Una vez seleccionado obtenido y entrenado los mejores modelos, entonces procederemos a hacer un Stacking de apilamiento de modelo, si jay mejoras combinando los modelos, nos uedamos con el Satacking y si por el contrario hay yn clasificador que lo hace mejor que este, entonnces, lo escogemos a l por su simplicidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.1'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelos():\n",
    "    randomForest=joblib.load('breast_cancerRandomForestV0.1.pkl')\n",
    "    logistic=joblib.load('breast_cancerLogisticRegressionV0.3.pkl') \n",
    "    supportVector= joblib.load('breast_cancerSupportVectorV0.1.pkl')\n",
    "    kneighbors=joblib.load('breast_cancerKNeighborsV0.1.pkl')\n",
    "    \n",
    "    return [randomForest,logistic,supportVector,kneighbors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_models=['RandomForest','LogisticRegression','SupportVector','Kneighbors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_models=cargar_modelos()\n",
    "base_learners=[(name,model.steps[1][1]) for name,model in zip(names_models[:-1],list_models[:-1])]\n",
    "base_learners.append((names_models[-1],list_models[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking=StackingClassifier(estimators=base_learners,\n",
    "                            final_estimator=LogisticRegression(class_weight='balanced'),\n",
    "                            cv=kfold,\n",
    "                            n_jobs=-1\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_models.append(stacking)\n",
    "names_models.append('StackingClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Analizado.. Ok\n",
      "LogisticRegression Analizado.. Ok\n",
      "SupportVector Analizado.. Ok\n",
      "Kneighbors Analizado.. Ok\n",
      "StackingClassifier Analizado.. Ok\n"
     ]
    }
   ],
   "source": [
    "df=select_best_model(names_models,list_models,scoring=('accuracy','f1'),X=X,y=y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.955505</td>\n",
       "      <td>0.942178</td>\n",
       "      <td>0.959263</td>\n",
       "      <td>0.947167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.948305</td>\n",
       "      <td>0.942230</td>\n",
       "      <td>0.952215</td>\n",
       "      <td>0.946731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SupportVector</th>\n",
       "      <td>0.950360</td>\n",
       "      <td>0.937579</td>\n",
       "      <td>0.954334</td>\n",
       "      <td>0.942164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kneighbors</th>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.954828</td>\n",
       "      <td>0.939122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StackingClassifier</th>\n",
       "      <td>0.952161</td>\n",
       "      <td>0.939905</td>\n",
       "      <td>0.956062</td>\n",
       "      <td>0.944488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy                  f1          \n",
       "                       train      test     train      test\n",
       "RandomForest        0.955505  0.942178  0.959263  0.947167\n",
       "LogisticRegression  0.948305  0.942230  0.952215  0.946731\n",
       "SupportVector       0.950360  0.937579  0.954334  0.942164\n",
       "Kneighbors          0.950617  0.932981  0.954828  0.939122\n",
       "StackingClassifier  0.952161  0.939905  0.956062  0.944488"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Podemos observar que el modelo de ensamblado no logro superar con mayor puntaje al resto de modelos, por lo que **RandomForest** queda escogido al presentar mayor puntaje que el resto de todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=list_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BestModel_breastCancer.pkl']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model,'BestModel_breastCancer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En conclucion desd mi punto de vista, el proyecto a concluido y ahora podemos hacer uso de **BestModel_breastCancer.pkl** como el mejor modelo a usar, listo para produccion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
